# -*- coding: utf-8 -*-
"""DIP_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GMgtMkUY1JtrbSYbDWdbCIQBdnM032C4
"""

# Commented out IPython magic to ensure Python compatibility.
import cv2
from matplotlib.pyplot import imread, imshow, imsave
# %matplotlib inline
from skimage.transform import resize
import matplotlib.pyplot as plt
 
import cv2
import re
import pickle 
import numpy as np
import pandas as pd

! pip install Pillow
! pip install pytesseract

! apt install tesseract-ocr
! apt install libtesseract-dev
import pytesseract
from pytesseract import Output

from google.colab import drive
drive.mount('/content/drive')

image=cv2.imread('/content/2.jpg')

original_image= image

gray= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)

edges= cv2.Canny(gray, 50,200)

contours, hierarchy= cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)


cv2.destroyAllWindows()


def get_contour_areas(contours):

    all_areas= []

    for cnt in contours:
        area= cv2.contourArea(cnt)
        all_areas.append(area)
    print('------------',all_areas)
    return all_areas


sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)


largest_item= sorted_contours[0]

#cv2.drawContours(original_image, largest_item, -1, (255,0,0),10)
cv2.drawContours(original_image, largest_item, -1, (255,0,0),10)
cv2.waitKey(0)
imshow(original_image)


cv2.waitKey(0)
cv2.destroyAllWindows()



gray1= cv2.cvtColor(original_image,cv2.COLOR_BGR2GRAY)
imshow(gray1)

image2=cv2.imread('/content/1.jpg')
gray2= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
imshow(gray2)

gray3=original_image-image2
gray4= cv2.cvtColor(gray3,cv2.COLOR_BGR2GRAY)
imshow(gray4)

(thresh, blackandwhite) = cv2.threshold(gray3, 88, 255, cv2.THRESH_BINARY)
imshow(blackandwhite)

height,width,channel = image.shape

width

height

gray4[300]

a=0
for i in range(width):
  if(gray4[300][i].any(0)):
    a=i
    break
a

b=0
for i in range(height):
  if(gray4[i][400].any(0)):
    b=i
    break  
b

c1=0
c=width
for i in range(width):
  c=c-1
  if(gray4[300][c].any(0)):
    c1=c
    break 
c1

d=height
d1=0
for i in range(height):
  d=d-1
  if(gray4[d][400].any(0)):
     d1=d
     break  
d1

d2=d1-b
c2=c1-a

def imcrop_without_loops( image, x, y, w, h):
       cropped_image=image[y:y+h,x:x+w,:] 
       return cropped_image

cropImage=imcrop_without_loops(image, a,b,c2,d2)
imshow(cropImage)

#resized_img = resize(cropImage, (1400,2000)) 
#plt.imshow(resized_img, cmap='gray', interpolation='none')

cropImage1=imcrop_without_loops(cropImage, 410,80,490,600)
imshow(cropImage1)  #1100/9

cropImage1

def day(cropImage,day):
  cropImageDay=imcrop_without_loops(cropImage, ((day-1)*45),0,45,500)
  #imshow(cropImageDay)  #day 1
  return cropImageDay
day1=day(cropImage1,1)
imshow(day1)



def resize(image,n1):

      # *** Your code Here ***
    height,width,channel = image.shape
    height=int((n1*40)+10)
    width=int(width)
    dim = (width, height)
    resized_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)   
    
    return resized_image
numofStd=21
k=resize(day1,numofStd)
imshow(k)

def OCR(image11):
   image = image11
 
   gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

 
 
   threshold_img = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
 # display image
   imshow(threshold_img)
 
   cv2.waitKey(0)
 
   cv2.destroyAllWindows()
  
   custom_config = r'--oem 3 --psm 6'
 # now feeding image to tesseract
   details = pytesseract.image_to_data(threshold_img, output_type=Output.DICT, config=custom_config, lang='eng')
   print(details.keys())
   total_boxes = len(details['text'])
   for sequence_number in range(total_boxes):
  	 if int(details['conf'][sequence_number]) >30:

 		  (x, y, w, h) = (details['left'][sequence_number], details['top'][sequence_number], details['width'][sequence_number],  details['height'][sequence_number])

 		  threshold_img = cv2.rectangle(threshold_img, (x, y), (x + w, y + h), (0, 255, 0), 2)
 # display image

   imshow( threshold_img)
 

   cv2.waitKey(0)
 # Destroying present windows on screen
   cv2.destroyAllWindows()
  
   custom_config = r'--oem 3 --psm 6'
 

   details = pytesseract.image_to_data(threshold_img, output_type=Output.DICT, config=custom_config, lang='eng')

   print(details.keys())
   parse_text = []
   word_list = []
   last_word = ''
   for word in details['text']:
       if word!='':
           word_list.append(word)
           last_word = word

       if (last_word!='' and word == '') or (word==details['text'][-1]):
           parse_text.append(word_list)
           word_list = []
   return parse_text

X=0
y=10
attendence=[]
for i in range (numofStd):
  cropSTDoneBYone=imcrop_without_loops(k, 5,X+y+8,35,35)
  X=X+40
  plt.imshow(cropSTDoneBYone)
  plt.show()
  l1=OCR(cropSTDoneBYone)  ##
  txt=" ".join(str(x) for x in l1)
  if (re.findall(r'[a]', txt)) :
    attendence.append('A')
    continue
  if (re.findall(r'[A]', txt)) :
    attendence.append('A')
    continue
  if ( re.findall(r'[1]', txt)) :
    attendence.append('L') 
    continue
  if (re.findall(r'[l]', txt)) :
    attendence.append('L') 
    continue
  if ( re.findall(r'[L]', txt)) :
    attendence.append('L')
    continue  
  else:
    attendence.append('P')  

  #=======================================PASS IMAGE ONE BY ONE TO CHECK A,P,L

attendence

L = list(item for item in range(1,22))

A = []
for i in range(0,21):
  A.append(attendence[i])

data_frame = pd.DataFrame(L,columns=['R'])

data_frame['Attendence'] = pd.Series(A, index=data_frame.index)
#data_frame['A'] = pd.Series(A, index=data_frame.index)
#data_frame['A'] = pd.Series(A, index=data_frame.index)
data_frame

from google.colab import drive
drive.mount('/content/drive')

source='DIP'
with open('/content/drive/MyDrive/'+ source  +'.csv', 'a',) as f:
  data_frame.to_csv(f,header=f.tell()==0)

#ff = pd.read_csv("attendence.csv").astype('float32')
ff=pd.read_json("/content/drive/MyDrive/attendence.json").astype('float32')
ff.shape

#X = ff.drop('label', axis=1)
#y = ff['label']
X = ff.drop('label',axis = 1)
print("shape:",X.shape)
print("culoms count:",len(X.iloc[1]))
print("784 = 28X28")
 
 
y = ff['label']
X.head()
 
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)
print(X_train.shape)
print(y_train.shape)
from sklearn.preprocessing import StandardScaler
np.unique(y)
X_train=X_train/255

from sklearn.svm import SVC
classifier = SVC(kernel='linear')
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test,y_pred)

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))

# THIS CELL IS RESRVERED FOR IMPORTS 
from skimage.color import rgb2gray
X1=0
y1=10

attendence=[]
for i in range (numofStd):
  cropSTDoneBYone=imcrop_without_loops(k, 5,X1+y1+8,28,28)
  X1=X1+40
  plt.imshow(cropSTDoneBYone)
  plt.show()
  grayscale = rgb2gray(cropSTDoneBYone)
  i=grayscale.reshape(784,)
  print(classifier.predict([i]))

from sklearn.model_selection import train_test_split
  
X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size = 0.30)
  

  
from sklearn.neighbors import KNeighborsClassifier
  
knn = KNeighborsClassifier(n_neighbors = 5)
  
knn.fit(X_train, y_train)

# THIS CELL IS RESRVERED FOR IMPORTS 
from skimage.color import rgb2gray
X1=0
y1=10
 
attendence=[]
for i in range (numofStd):
  cropSTDoneBYone=imcrop_without_loops(k, 5,X1+y1+8,28,28)
  X1=X1+40
  plt.imshow(cropSTDoneBYone)
  plt.show()
  grayscale = rgb2gray(cropSTDoneBYone)
  i=grayscale.reshape(784,)
  print(knn.predict([i]))